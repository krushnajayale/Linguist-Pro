{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oC-_BCZkPeZe",
        "outputId": "80b87503-968c-4218-ef47-ff88218c0258"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/981.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m138.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m135.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q streamlit pyngrok transformers sentencepiece langdetect torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import json\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from langdetect import detect, DetectorFactory\n",
        "from morse_dict import MORSE_CODE_DICT\n",
        "\n",
        "DetectorFactory.seed = 0\n",
        "\n",
        "# ---------------- PAGE CONFIG ----------------\n",
        "st.set_page_config(\n",
        "    page_title=\"Linguist Pro\",\n",
        "    page_icon=\"ğŸŒ\",\n",
        "    layout=\"wide\",\n",
        "    initial_sidebar_state=\"expanded\"\n",
        ")\n",
        "\n",
        "# ---------------- STYLING ----------------\n",
        "st.markdown(\"\"\"\n",
        "<style>\n",
        ".stApp {\n",
        "    background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);\n",
        "}\n",
        ".title-text {\n",
        "    font-weight: 800;\n",
        "    color: #1e3a8a;\n",
        "    text-align: center;\n",
        "}\n",
        ".subtitle-text {\n",
        "    color: #64748b;\n",
        "    text-align: center;\n",
        "}\n",
        ".result-box {\n",
        "    background-color: #f8fafc;\n",
        "    border: 2px solid #3b82f6;\n",
        "    border-radius: 12px;\n",
        "    padding: 1.5rem;\n",
        "    min-height: 150px;\n",
        "    font-size: 1.1rem;\n",
        "}\n",
        "</style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# ---------------- NLLB LANGUAGE MAP ----------------\n",
        "NLLB_LANGS = {\n",
        "    \"English\": \"eng_Latn\",\n",
        "    \"Hindi\": \"hin_Deva\",\n",
        "    \"Marathi\": \"mar_Deva\",\n",
        "    \"French\": \"fra_Latn\",\n",
        "    \"German\": \"deu_Latn\",\n",
        "    \"Spanish\": \"spa_Latn\"\n",
        "}\n",
        "\n",
        "# ---------------- LOAD GEN-Z DICTIONARY ----------------\n",
        "with open(\"genz_slang.json\", \"r\") as f:\n",
        "    GENZ_DICT = json.load(f)\n",
        "\n",
        "# ---------------- MORSE UTILITIES ----------------\n",
        "def is_morse(text):\n",
        "    return all(c in \".-/ \" for c in text.strip())\n",
        "\n",
        "def decode_morse(morse_text):\n",
        "    words = morse_text.split(\" / \")\n",
        "    decoded = []\n",
        "    for word in words:\n",
        "        letters = word.split()\n",
        "        decoded.append(\"\".join(MORSE_CODE_DICT.get(l, \"\") for l in letters))\n",
        "    return \" \".join(decoded)\n",
        "\n",
        "# ---------------- GEN-Z NORMALIZATION ----------------\n",
        "def normalize_genz(text):\n",
        "    words = text.split()\n",
        "    return \" \".join(GENZ_DICT.get(w.lower(), w) for w in words)\n",
        "\n",
        "# ---------------- LANGUAGE DETECTION ----------------\n",
        "def detect_language(text):\n",
        "    try:\n",
        "        return detect(text)\n",
        "    except:\n",
        "        return \"unknown\"\n",
        "\n",
        "# ---------------- LOAD NLLB MODEL ----------------\n",
        "@st.cache_resource\n",
        "def load_nllb():\n",
        "    model_name = \"facebook/nllb-200-distilled-600M\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "    return tokenizer, model\n",
        "\n",
        "tokenizer, model = load_nllb()\n",
        "\n",
        "def translate_text(text, src_lang, tgt_lang):\n",
        "    tokenizer.src_lang = src_lang\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True)\n",
        "    generated = model.generate(\n",
        "        **inputs,\n",
        "        forced_bos_token_id=tokenizer.convert_tokens_to_ids(tgt_lang),\n",
        "        max_length=256\n",
        "    )\n",
        "    return tokenizer.decode(generated[0], skip_special_tokens=True)\n",
        "\n",
        "# ---------------- SESSION STATE ----------------\n",
        "if \"history\" not in st.session_state:\n",
        "    st.session_state.history = []\n",
        "if \"last_translation\" not in st.session_state:\n",
        "    st.session_state.last_translation = \"\"\n",
        "\n",
        "# ---------------- SIDEBAR ----------------\n",
        "with st.sidebar:\n",
        "    st.title(\"ğŸ“œ History\")\n",
        "    if not st.session_state.history:\n",
        "        st.info(\"No translations yet.\")\n",
        "    else:\n",
        "        for item in reversed(st.session_state.history):\n",
        "            with st.expander(f\"{item['src']} âœ {item['tgt']}\"):\n",
        "                st.write(\"**Original:**\", item[\"text\"])\n",
        "                st.write(\"**Translated:**\", item[\"translated\"])\n",
        "    if st.button(\"Clear History\"):\n",
        "        st.session_state.history = []\n",
        "        st.rerun()\n",
        "\n",
        "# ---------------- MAIN UI ----------------\n",
        "st.markdown('<h1 class=\"title-text\">Linguist Pro</h1>', unsafe_allow_html=True)\n",
        "st.markdown('<p class=\"subtitle-text\">Powered by NLLB-200</p>', unsafe_allow_html=True)\n",
        "\n",
        "src_ui, _, tgt_ui = st.columns([4,1,4])\n",
        "\n",
        "with src_ui:\n",
        "    src_lang = st.selectbox(\"From\", [\"Auto Detect\"] + list(NLLB_LANGS.keys()))\n",
        "with tgt_ui:\n",
        "    tgt_lang = st.selectbox(\"To\", list(NLLB_LANGS.keys()), index=1)\n",
        "\n",
        "input_text = st.text_area(\n",
        "    \"Enter text\",\n",
        "    placeholder=\"Gen-Z slang â€¢ Morse â€¢ Multilingual\",\n",
        "    height=200\n",
        ")\n",
        "\n",
        "if st.button(\"Translate Now\", type=\"primary\", use_container_width=True):\n",
        "    if input_text.strip():\n",
        "        with st.spinner(\"Translating with NLLB intelligence...\"):\n",
        "\n",
        "            if is_morse(input_text):\n",
        "                input_text = decode_morse(input_text)\n",
        "\n",
        "            input_text = normalize_genz(input_text)\n",
        "\n",
        "            detected = detect_language(input_text)\n",
        "            src_code = NLLB_LANGS[src_lang] if src_lang != \"Auto Detect\" else NLLB_LANGS.get(\n",
        "                next((k for k,v in NLLB_LANGS.items() if v.startswith(detected)), \"English\")\n",
        "            )\n",
        "\n",
        "            translated = translate_text(\n",
        "                input_text,\n",
        "                src_code,\n",
        "                NLLB_LANGS[tgt_lang]\n",
        "            )\n",
        "\n",
        "            st.session_state.last_translation = translated\n",
        "            st.session_state.history.append({\n",
        "                \"src\": src_code,\n",
        "                \"tgt\": NLLB_LANGS[tgt_lang],\n",
        "                \"text\": input_text,\n",
        "                \"translated\": translated\n",
        "            })\n",
        "\n",
        "if st.session_state.last_translation:\n",
        "    st.markdown(\"### Translation Output\")\n",
        "    st.markdown(\n",
        "        f\"<div class='result-box'>{st.session_state.last_translation}</div>\",\n",
        "        unsafe_allow_html=True\n",
        "    )\n",
        "    st.code(st.session_state.last_translation)\n",
        "\n",
        "st.markdown(\"---\")\n",
        "st.markdown(\n",
        "    \"<p style='text-align:center;color:#94a3b8;'>Streamlit â€¢ NLLB-200 â€¢ Advanced NLP</p>\",\n",
        "    unsafe_allow_html=True\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h65s8CiUPzMZ",
        "outputId": "12366950-14e2-454b-ed8f-e50960a3dcd1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile morse_dict.py\n",
        "MORSE_CODE_DICT = {\n",
        "    \".-\": \"A\", \"-...\": \"B\", \"-.-.\": \"C\", \"-..\": \"D\",\n",
        "    \".\": \"E\", \"..-.\": \"F\", \"--.\": \"G\", \"....\": \"H\",\n",
        "    \"..\": \"I\", \".---\": \"J\", \"-.-\": \"K\", \".-..\": \"L\",\n",
        "    \"--\": \"M\", \"-.\": \"N\", \"---\": \"O\", \".--.\": \"P\",\n",
        "    \"--.-\": \"Q\", \".-.\": \"R\", \"...\": \"S\", \"-\": \"T\",\n",
        "    \"..-\": \"U\", \"...-\": \"V\", \".--\": \"W\", \"-..-\": \"X\",\n",
        "    \"-.--\": \"Y\", \"--..\": \"Z\",\n",
        "    \"/\": \" \"\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaKwyOqERSnz",
        "outputId": "a983f6b1-cf7d-41b1-837b-90af9c2e23ba"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing morse_dict.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile genz_slang.json\n",
        "{\n",
        "  \"bruh\": \"brother\",\n",
        "  \"mid\": \"average\",\n",
        "  \"lit\": \"amazing\",\n",
        "  \"sus\": \"suspicious\",\n",
        "  \"fr\": \"for real\",\n",
        "  \"ngl\": \"not going to lie\",\n",
        "  \"bro\": \"brother\",\n",
        "  \"idk\": \"i do not know\",\n",
        "  \"imo\": \"in my opinion\"\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmBevgftRXTK",
        "outputId": "e7ef3db7-e40e-4e4f-cf8e-b45541732b36"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing genz_slang.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken 37T04ZcKwd4sYFMCXZtaOjFFOOY_31t8dTZk8nkR7UppVF2Ka"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icQ3bO0dQgEe",
        "outputId": "a6cbe174-6bd4-4139-eb79-7d827b471e7a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py &>/content/logs.txt &"
      ],
      "metadata": {
        "id": "Ri241i2XQFpA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "public_url = ngrok.connect(8501)\n",
        "public_url\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDGpEGmCQOrF",
        "outputId": "a868dd69-1d31-42bf-f55e-7b7a9dba13d7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<NgrokTunnel: \"https://acyclic-hortensia-unwatched.ngrok-free.dev\" -> \"http://localhost:8501\">"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    }
  ]
}